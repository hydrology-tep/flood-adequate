{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Sentinel-1 backscatter profile for reference image used in flood analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This application takes a number of Sentinel-1 stack products and identifies a possible reference product for flood change detection analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"quicklink\">Quick link\n",
    "\n",
    "* [Objective](#objective)\n",
    "* [Data](#data)\n",
    "* [Service Definition](#service)\n",
    "* [Parameter Definition](#parameter)\n",
    "* [Runtime Parameter Definition](#runtime)\n",
    "* [Workflow](#workflow)\n",
    "* [Strengths and Limitations](#strengths-limitations) \n",
    "* [License](#license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"objective\">Objective \n",
    "\n",
    "The objective of this practice is to determine the backscatter profiles of a stack of Sentinel-1 GRD datasets and rapidly and reliably extract the most adequate reference image from the stack.\n",
    "\n",
    "### <a name=\"testsite\">Methodology\n",
    "\n",
    "We apply here the principles descrbed by [Hostache et al., 2012, Change detection approaches for flood extent mapping: How to select the most adequate reference image from online archives?](https://www.researchgate.net/publication/230627460_Change_detection_approaches_for_flood_extent_mapping_How_to_select_the_most_adequate_reference_image_from_online_archives)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"data\">Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "SENTINEL data products are made available systematically and free of charge to all data users including the general public, scientific and commercial users. Radar data will be delivered within an hour of reception for Near Real-Time (NRT) emergency response, within three hours for NRT priority areas and within 24 hours for systematically archived data.\n",
    "\n",
    "All data products are distributed in the SENTINEL Standard Archive Format for Europe (SAFE) format.\n",
    "\n",
    "Data products are available in single polarisation (VV or HH) for Wave mode and dual polarisation (VV+VH or HH+HV) and single polarisation (HH or VV) for SM, IW and EW modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Level-1 Ground Range Detected (GRD) products consist of focused SAR data that has been detected, multi-looked and projected to ground range using an Earth ellipsoid model. Phase information is lost. The resulting product has approximately square resolution pixels and square pixel spacing with reduced speckle at the cost of reduced geometric resolution.\n",
    "\n",
    "GRD products can be in one of three resolutions:\n",
    "\n",
    "* Full Resolution (FR)\n",
    "* High Resolution (HR)\n",
    "* Medium Resolution (MR).\n",
    "\n",
    "The resolution is dependent upon the amount of multi-looking performed. Level-1 GRD products are available in MR and HR for IW and EW modes, MR for WV mode and MR, HR and FR for SM mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Sentinel-1 backscatter profile for reference image used in flood analysis'),\n",
    "                ('abstract', 'This application takes a number of Sentinel-1 stack products and identifies a possible reference product for flood change detection analysis '),\n",
    "                ('id', 'ewf-notebook-stagein-2')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the Sentinel-1 stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ( 'S1A_IW_GRDH_1SDV_20180710T210820_20180710T210845_022737_0276D8_EE0D', 'S1A_IW_GRDH_1SDV_20180628T210819_20180628T210844_022562_0271AB_5EC9', 'S1A_IW_GRDH_1SDV_20180616T210818_20180616T210843_022387_026C91_2BFC', 'S1A_IW_GRDH_1SDV_20180604T210817_20180604T210842_022212_02672C_A700', 'S1A_IW_GRDH_1SDV_20180523T210817_20180523T210842_022037_0261A2_F2E6', 'S1A_IW_GRDH_1SDV_20180511T210816_20180511T210841_021862_025C14_BB6B', 'S1A_IW_GRDH_1SDV_20180429T210815_20180429T210840_021687_02567D_7268', 'S1A_IW_GRDH_1SDV_20180417T210815_20180417T210840_021512_025107_8E61', 'S1A_IW_GRDH_1SDV_20180405T210814_20180405T210839_021337_024B86_EDB0', 'S1A_IW_GRDH_1SDV_20180324T210814_20180324T210839_021162_02460C_D571', 'S1A_IW_GRDH_1SDV_20180312T210814_20180312T210839_020987_02407D_A2E6', 'S1A_IW_GRDH_1SDV_20180228T210814_20180228T210839_020812_023AF6_1868' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the Sentinel-1 stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = ( 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180710T210820_20180710T210845_022737_0276D8_EE0D', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180628T210819_20180628T210844_022562_0271AB_5EC9', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180616T210818_20180616T210843_022387_026C91_2BFC', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180604T210817_20180604T210842_022212_02672C_A700', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180523T210817_20180523T210842_022037_0261A2_F2E6', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180511T210816_20180511T210841_021862_025C14_BB6B', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180429T210815_20180429T210840_021687_02567D_7268', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180417T210815_20180417T210840_021512_025107_8E61', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180405T210814_20180405T210839_021337_024B86_EDB0', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180324T210814_20180324T210839_021162_02460C_D571', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180312T210814_20180312T210839_020987_02407D_A2E6', 'https://catalog.terradue.com//sentinel1/series/GRD/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180228T210814_20180228T210839_020812_023AF6_1868')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/workspace/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aoi = dict([('id', 'aoi'),\n",
    "               ('value', 'POLYGON ((133.06 34.37, 133.06 34.57, 132.86 34.57, 132.86 34.37, 133.06 34.37))'),\n",
    "               ('title', 'Area of interest (WKT)'),\n",
    "               ('abstract', 'Area of interest in Well-known text)')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "s1meta = \"manifest.safe\"\n",
    "\n",
    "products = []\n",
    "\n",
    "for s1path in input_identifiers:\n",
    "\n",
    "    s1prd= \"%s/%s/%s.SAFE/%s\" % (data_path, s1path, s1path, s1meta)\n",
    "    reader = ProductIO.getProductReader(\"SENTINEL-1\")\n",
    "    product = reader.readProductNodes(s1prd, None)\n",
    "    products.append(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Extract information about the Sentinel-1 GRD products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: S1A_IW_GRDH_1SDV_20180710T210820_20180710T210845_022737_0276D8_EE0D, 25258 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180628T210819_20180628T210844_022562_0271AB_5EC9, 25258 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180616T210818_20180616T210843_022387_026C91_2BFC, 25257 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180604T210817_20180604T210842_022212_02672C_A700, 25259 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180523T210817_20180523T210842_022037_0261A2_F2E6, 25258 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180511T210816_20180511T210841_021862_025C14_BB6B, 25259 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180429T210815_20180429T210840_021687_02567D_7268, 25258 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180417T210815_20180417T210840_021512_025107_8E61, 25258 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180405T210814_20180405T210839_021337_024B86_EDB0, 25257 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180324T210814_20180324T210839_021162_02460C_D571, 25258 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180312T210814_20180312T210839_020987_02407D_A2E6, 25259 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n",
      "Product: S1A_IW_GRDH_1SDV_20180228T210814_20180228T210839_020812_023AF6_1868, 25259 x 16733 pixels\n",
      "Bands:   ['Amplitude_VH', 'Intensity_VH', 'Amplitude_VV', 'Intensity_VV']\n"
     ]
    }
   ],
   "source": [
    "for product in products:\n",
    "\n",
    "    width = product.getSceneRasterWidth()\n",
    "    height = product.getSceneRasterHeight()\n",
    "    name = product.getName()\n",
    "    band_names = product.getBandNames()\n",
    "    print(\"Product: %s, %d x %d pixels\" % (name, width, height))\n",
    "    print(\"Bands:   %s\" % (list(band_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Process the data\n",
    "\n",
    "* Step 0: Data preparation - Subset\n",
    "* Step 1: Pre-processing - Calibration\n",
    "* Step 2: Pre-processing - Speckle filtering\n",
    "* Step 3: Pre-processing - Linear to dB\n",
    "* Step 4: Distribution analysis and probability density function fitting\n",
    "* Step 5: Anomaly index 1 - Backscattering spread\n",
    "* Step 6: Anomaly index 2 - Backscattering statistical distribution distance\n",
    "* Step 7: Anomaly index 3 - Final score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <a name=\"subset\">Step 0: Data preparation - Subset\n",
    "\n",
    "We extract a subset of the Sentinel-1 GRD products by specify a rectangle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "import snappy\n",
    "\n",
    "WKTReader = snappy.jpy.get_type('com.vividsolutions.jts.io.WKTReader')\n",
    "\n",
    "geom = WKTReader().read(aoi['value']);\n",
    "\n",
    "HashMap = jpy.get_type('java.util.HashMap')    \n",
    "GPF.getDefaultInstance().getOperatorSpiRegistry().loadOperatorSpis()\n",
    "\n",
    "parameters = HashMap()\n",
    "parameters.put('copyMetadata', True)\n",
    "parameters.put('geoRegion', geom)\n",
    "\n",
    "subsets = []\n",
    "\n",
    "for product in products:\n",
    "\n",
    "    subset = GPF.createProduct('Subset', parameters, product)\n",
    "    subsets.append(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <a name=\"calibration\">Step 1: Pre-processing - Calibration\n",
    "\n",
    "The objective of SAR calibration is to provide imagery in which the pixel values can be directly related to the radar backscatter of the scene. Though uncalibrated SAR imagery is sufficient for qualitative use, calibrated SAR images are essential to quantitative use of SAR data.\n",
    "\n",
    "Typical SAR data processing, which produces level 1 images, does not include radiometric corrections and significant radiometric bias remains. Therefore, it is necessary to apply the radiometric correction to SAR images so that the pixel values of the SAR images truly represent the radar backscatter of the reflecting surface. The radiometric correction is also necessary for the comparison of SAR images acquired with different sensors, or acquired from the same sensor but at different times, in different modes, or processed by different processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "parameters = HashMap()\n",
    "\n",
    "parameters.put('auxFile', 'Latest Auxiliary File')\n",
    "parameters.put('outputSigmaBand', True)\n",
    "parameters.put('selectedPolarisations', 'VV')\n",
    "\n",
    "calibrates = []\n",
    "\n",
    "for subset in subsets:\n",
    "\n",
    "    calibrate = GPF.createProduct('Calibration', parameters, subset)\n",
    "    calibrates.append(calibrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <a name=\"speckle\">Step 2: Pre-processing - Speckle filtering\n",
    "\n",
    "SAR images have inherent salt and pepper like texturing called speckles which degrade the quality of the image and make interpretation of features more difficult. Speckles are caused by random constructive and destructive interference of the de-phased but coherent return waves scattered by the elementary scatters within each resolution cell. Speckle noise reduction can be applied either by spatial filtering or multilook processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "parameters = HashMap()\n",
    "\n",
    "parameters.put('filter', 'Lee')\n",
    "parameters.put('filterSizeX', 7)\n",
    "parameters.put('filterSizeY', 7)\n",
    "parameters.put('dampingFactor', 2)\n",
    "parameters.put('edgeThreshold', 5000.0)\n",
    "parameters.put('estimateENL', True)\n",
    "parameters.put('enl', 1.0)\n",
    "\n",
    "speckles = []\n",
    "\n",
    "for calibrate in calibrates:\n",
    "\n",
    "    speckle = GPF.createProduct('Speckle-Filter', parameters, calibrate)\n",
    "    speckles.append(speckle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <a name=\"lineartodb\">Step 3: Pre-processing - Linear to dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = HashMap()\n",
    "\n",
    "lineartodbs= []\n",
    "dates = [];\n",
    "\n",
    "for speckle in speckles : \n",
    "\n",
    "    lineartodb = GPF.createProduct('linearToFromdB', parameters, speckle)\n",
    "    lineartodbs.append(lineartodb)\n",
    "    name = lineartodb.getName()\n",
    "    timestamp = name.split(\"_\")[5] \n",
    "    date = timestamp[:8]\n",
    "    dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import gc \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plotBand(product, band, vmin, vmax):\n",
    "     \n",
    "    band = product.getBand(band)\n",
    "\n",
    "    w = band.getRasterWidth()\n",
    "    h = band.getRasterHeight()\n",
    "\n",
    "    band_data = np.zeros(w * h, np.float32)\n",
    "    band.readPixels(0, 0, w, h, band_data)\n",
    "\n",
    "    band_data.shape = h, w\n",
    "\n",
    "    imgplot = plt.imshow(band_data, cmap=plt.cm.binary_r, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    \n",
    "    return imgplot \n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "i = 1\n",
    "\n",
    "n_rows = int(round(float(len(input_identifiers))/3))\n",
    "\n",
    "for lineartodb in lineartodbs :\n",
    "     \n",
    "        a=fig.add_subplot(n_rows, 3, 0+i)\n",
    "        imgplot = plotBand(lineartodb, 'Sigma0_VV_db', -25, 5)\n",
    "        name = lineartodb.getName()\n",
    "        timestamp = name.split(\"_\")[5] \n",
    "        date = timestamp[:8]\n",
    "        a.set_title(date)\n",
    "        i = i+1\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()\n",
    "plt.show()\n",
    "\n",
    "fig.clf()\n",
    "plt.close()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a name=\"distribution\">Step 4: Distribution analysis and probability density function fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To determine the backscatering profile of each image sample, the backscaterring vales distribution in the image must be analyzed and expressed with a probability distribution function.\n",
    "In this processing step, we use a normal distribution to fit our values. We then save the mean and standard deviation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy import stats \n",
    "\n",
    "pdf_params = []\n",
    "lnspc = np.linspace(-25, 5, 2048)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plotHistdB(lineartodb, band):\n",
    "\n",
    "    band = lineartodb.getBand(band)\n",
    "\n",
    "    w = band.getRasterWidth()\n",
    "    h = band.getRasterHeight()\n",
    "\n",
    "    band_data = np.zeros(w * h, np.float32)\n",
    "    band.readPixels(0, 0, w, h, band_data)\n",
    "    band_data.shape = h * w\n",
    "\n",
    "    ser = np.asarray(band_data, dtype='float')\n",
    "    \n",
    "    m, s = stats.norm.fit(ser) # get mean and standard deviation  \n",
    "    pdf_params.append([m,s])\n",
    "    p5 = np.percentile(ser, 5) # return 5th percentile.\n",
    "    p95 = np.percentile(ser, 95) # return 95th percentile.\n",
    "    index1 = p95 - p5 # anomaly index 1\n",
    "    index1s.append(index1)\n",
    "    \n",
    "    hist = plt.hist(ser, bins=2048, range=[-25, 5], normed=True)\n",
    "    pdf_g = stats.norm.pdf(lnspc, m, s) # now get theoretical values in our interval\n",
    "    pdf = plt.plot(lnspc, pdf_g, label=\"Norm\", c='r') # plot it\n",
    "    plt.xlabel('Backscatter [dB]')\n",
    "    plt.ylabel('Pixels distribution')\n",
    "    \n",
    "    return hist\n",
    "\n",
    "index1s = []\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "i = 1\n",
    "\n",
    "for lineartodb in lineartodbs :\n",
    "    \n",
    "        a=fig.add_subplot(n_rows, 3, 0+i)\n",
    "        a.patch.set_alpha(0.7)\n",
    "        plotHistdB(lineartodb, 'Sigma0_VV_db')\n",
    "        a.set_title(dates[i-1])\n",
    "        i = i+1\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()\n",
    "plt.show()\n",
    "fig.clf()\n",
    "plt.close()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a name=\"anomaly1\">Step 5: Anomaly index 1 - Backscattering spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A flood image contains an exceptionally high number of pixels with very low backscatter values. Moreover, in the event of a flood, soils are in general wet and often close to saturation. \n",
    "Therefore, a first anomaly index1 should express an image’s spread in the distribution of backscattering values. There is a high likelihood that images exhibiting an irregularly large spread are affected by flooding. The proposed index expresses the distance between the 5% and 95% percentiles inferred from the image histogram. The 5% (resp. 95%) percentile is the backscatter value below which 5% (resp. 95%) of the observations are to be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datespc = np.linspace(1, len(dates), len(dates))\n",
    "\n",
    "index1normalized = (index1s-min(index1s))/(max(index1s)-min(index1s))\n",
    "plt.scatter(datespc, index1normalized)\n",
    "plt.xticks(datespc, dates, rotation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()\n",
    "plt.show()\n",
    "fig.clf()\n",
    "plt.close()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a name=\"anomaly2\">Step 6: Anomaly index 2 - Backscattering statistical distribution distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second anomaly index2 evaluates the degree to which the backscatter distribution inferred from one image reflects the backscattering behaviour inferred from the full sample. The main idea here is that a reference image for flood detection is required to have a statistical distribution of backscatter values that closely follows the median distribution inferred from a representative sample of candidate images. Anomaly index2 quantifies the distance between the backscatter statistical distribution of a candidate image and the median backscatter statistical distribution over the sample of candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm \n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "color=iter(cm.rainbow(np.linspace(0,1,len(lineartodbs)+1)))\n",
    "i = 1\n",
    "arr = np.array(pdf_params)\n",
    "median = np.median(arr, axis=0)\n",
    "a=fig.add_subplot(121)\n",
    "a.patch.set_alpha(0.7)\n",
    "\n",
    "index2s = []\n",
    "\n",
    "# Cumulative distributions:\n",
    "for lineartodb in lineartodbs :\n",
    "\n",
    "\n",
    "        lnspc = np.linspace(-25, 5, 2048)\n",
    "\n",
    "        cdf_g = stats.norm.cdf(lnspc, pdf_params[i-1][0], pdf_params[i-1][1])\n",
    "\n",
    "        #sorted_ser = np.sort(ser)  # Or data.sort(), if data can be modified\n",
    "\n",
    "        c=next(color)\n",
    "        cdf = plt.plot(lnspc, cdf_g, label=dates[i-1], c=c) # plot it\n",
    "        #plt.step(sorted_ser, np.arange(sorted_ser.size), c=c)  # From 0 to the number of data points-1\n",
    "        #plt.step(sorted_ser[::-1], np.arange(sorted_ser.size))  # From the number of data points-1 to 0\n",
    "\n",
    "        index2 = math.fabs((median[0]-pdf_params[i-1][0]))\n",
    "        index2s.append(index2)\n",
    "\n",
    "        i = i +1\n",
    "\n",
    "\n",
    "cdf_g = stats.norm.cdf(lnspc, median[0], median[1])\n",
    "c=next(color)\n",
    "cdf = plt.plot(lnspc, cdf_g, label=\"median\", c=c)\n",
    "plt.legend()\n",
    "\n",
    "a = fig.add_subplot(122)\n",
    "\n",
    "index2sa = np.asarray(index2s)\n",
    "index2normalized = (index2sa-min(index2sa))/(max(index2sa)-min(index2sa))\n",
    "plt.scatter(datespc, index2normalized, c='g')\n",
    "plt.xticks(datespc, dates, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a name=\"anomaly3\">Step 7: Anomaly index 3 - Final score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compromise solution would be to identify the best reference image within the candidate list by combining the anomaly indexes 1 and 2.\n",
    "While it is helpful to first consider the two anomaly indexes separately, the best reference image for flood mapping applications may arguably be the candidate image having the lowest index3 value. A value close to 0 is assigned to an image that is comparatively dry and representative for an area’s normal backscattering behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index3 = np.sqrt(np.power(index1normalized,2)+np.power(index2normalized,2))\n",
    "index3normalized = (index3-min(index3))/(max(index3)-min(index3))\n",
    "\n",
    "plt.scatter(datespc, index1normalized, c='b')\n",
    "plt.scatter(datespc, index2normalized, c='g')\n",
    "plt.scatter(datespc, index3, c='r')\n",
    "plt.xticks(datespc, dates, rotation='vertical')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <a name=\"license\">License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
